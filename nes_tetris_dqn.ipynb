{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nes_tetris_dqn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIdOf2e8ub3A"
      },
      "source": [
        "#NES Tetris DQN\r\n",
        "\r\n",
        "###Introduction\r\n",
        "\r\n",
        "###Status:\r\n",
        "Implementing base gym environment\r\n",
        "\r\n",
        "Agent will use different attributes of the  current board state to evaluate the EV of each possible move, and then executes said move.\r\n",
        "\r\n",
        "Get possible moves -> evaluate the state of each move -> select the move with the best EV\r\n",
        "\r\n",
        "###Implemented:\r\n",
        "- Base board state\r\n",
        "- Added new piece creation and handling of next pieces\r\n",
        "- Added basic rendering of board and piece info\r\n",
        "- Added moving and rotating of pieces\r\n",
        "- Added validation of pieces and moves\r\n",
        "- Added getting of valid moves in current state\r\n",
        "- Added wrapper function for moving piece in board\r\n",
        "- Added checking whether a piece should be set on the board\r\n",
        "- Added above function into wrapper move function in board\r\n",
        "- Added checking whether a piece should end the game / top off\r\n",
        "- Added reverting of move when illegal move is made (used when player tops off)\r\n",
        "- Added natural piece drop (available moves will reflect the natural drop if present)\r\n",
        "- Added line clears and checking for line clears\r\n",
        "- Added updating of levels\r\n",
        "- Added scoring system\r\n",
        "- Added returning of board state\r\n",
        "- Added option to force single direction movement in get_available_moves\r\n",
        "- Added openai gym env\r\n",
        "- Added agent\r\n",
        "- Added setup and learning of agent\r\n",
        "- Tidied up training\r\n",
        "- Attempt to tune the agent for better performance\r\n",
        "- Add features from Dellacherie's Algorithm for agent\r\n",
        "- Fixed board states not having a new copy of the original pieces_table\r\n",
        "\r\n",
        "###Issues:\r\n",
        "\r\n",
        "###To Implement:\r\n",
        "Add checking in piece class for illegal moves (right now validation is only done at the board level), will need to reference the board by passing in the board in the function parameters\r\n",
        "\r\n",
        "Add support for earlier levels (where it can take several moves before a piece falls down)\r\n",
        "\r\n",
        "Add support for tucks (have to check the frames to see if it can be done)\r\n",
        "\r\n",
        "###Agent Status:\r\n",
        "- Contemporary tetris agent's features are being used, however, the result is not very good. Most features are being pulled from Dellacherie's Algorithm, which has proven results.\r\n",
        "- This setup of NES Tetris differs from conventional Tetris simulations. These may explain why the agent struggles at the moment. Notable differences are:\r\n",
        "  1. Conventional setups do not enforce a forced drop, and thus are able to move pieces perfectly. The current setup will automatically drop pieces depending on the frame count. This constrains the ability for the agent to get pieces into an optimal position, and I believe that this is the major issue that the agent faces. For instance, at level 18, a piece drops 2 cells for every move it makes.\r\n",
        "  2. Conventional setups may sometimes allow holding of pieces, while NES does not. This prevents the agent from possibly getting out of unlucky piece sequence, although it is nowhere near that level of doing so.\r\n",
        "  3. Certain setups use a random \"7-bag\" system, which is in place for most modern versions of Tetris. This system enforces the complete set of pieces to be used, albeit randomly arranged. As such, there is consistency in gameplay, whereas the setup used here is truly random, meaning that the agent can lose at some point due to a bad piece sequence.\r\n",
        "- When considering a piece, the agent simulates the piece being hard dropped and evaluates it as such.\r\n",
        "- Note: The aim of this project is NOT to create an agent that performs as many line clears as possible. The aim is to design an agent that can not only stack efficiently, but also score well with a fixed set of line clears (230 lines for NES Tetris). Ideally, we'd be able to have an agent that can play the entire game of NES Tetris, including the transition and kill screen.\r\n",
        "\r\n",
        "* Personal best\r\n",
        "* Total Games:  550\r\n",
        "* Took total / per game (seconds): 633.1551685333252 / 12.663103404045104\r\n",
        "* Total Steps:  132296\r\n",
        "* Epsilon:  0.0001\r\n",
        "*\r\n",
        "* Average:  533.06 / 230.72\r\n",
        "* Median:  303.0 / 0.0\r\n",
        "* Mean:  533.06 / 230.72\r\n",
        "* Min:  228 / 0\r\n",
        "* Max:  2566 / 2163\r\n",
        "\r\n",
        "###Goals:\r\n",
        "- Get an agent to stack flat in the first place\r\n",
        "- Get an agent to stack efficiently in 9 columns\r\n",
        "\r\n",
        "###Features Explored:\r\n",
        "Commonly used features such as landing height and transitions are used. Several more are introduced, which should allow the agent to perform better:\r\n",
        "  1. \r\n",
        "\r\n",
        "- Possible improvements:\r\n",
        "  1. Add future moves for the agent to use / consider. Right now, the agent only considers moving left or right once. This can be expanded to moving twice or even thrice. This requires more computation, but can possibly help the agent work better.\r\n",
        "  2. Enforce general NES Tetris strategies. This includes adding features that correspond to building on the left, keeping a right well. \r\n",
        "\r\n",
        "###Emulating a real player\r\n",
        "- Players tend to maintain a right well, and stack efficiently in the leftmost 9 columns. This can be done via a binary value, where the agent checks the presence of a right well (or if any well for that matter), and also to check the current piece ID if the right well is present. Typically, right wells are preferred, because it is perceived to be harder to play with a center well. Ideally, the agent just stacks on the 9 left columns, and specifically ignores the right well until it gets an I piece. So if a move will result in a right well being disrupted, then the feature should heavily discourage it. If an I piece is present with the presence of a right well (and possibly the ability to tetris), then the feature should heavily encourage it.\r\n",
        "\r\n",
        "- Players tend to build on the left. The left side of the board is disadvantaged in terms of getting pieces to the desired side. However, players tend to throw pieces to the left at every opportunity, to minimise the risk of topping off because they can easily throw pieces to the right in an emergency. The most basic way to implement this is to just check for the x-coordinate of the resulting move, but this can be potentially dangerous if the agent keeps moving to the left. We can introduce the checking of board height / landing height too, in order to balance this out.\r\n",
        "\r\n",
        "- Players might play low (MIGHT, this is a risk-reward balance that players have to follow). Ideally, players play low and score Tetrises, but they may not be able to do so all the time. A basic implementation of this can just involve the average board height and the landing height too. These features are used in the previous point, so there's kinda a connection between the two.\r\n",
        "\r\n",
        "###Training\r\n",
        "- Due to the exploratory nature of Q-learning, the agent generally performs terribly until it stops exploring, due to the random nature of moves. As documented in https://github.com/nuno-faria/tetris-ai, the agent tends to only perform decently towards the end of exploring. This corresponds to what we're seeing with the NES agent too, except that it performs way worse.\r\n",
        "- After training, we will need to observe how the agent attempts to move and stack pieces, and then tune the features to try to encourage better gameplay.\r\n",
        "\r\n",
        "\r\n",
        "###References:\r\n",
        "https://codemyroad.wordpress.com/2013/04/14/tetris-ai-the-near-perfect-player/\r\n",
        "https://github.com/michiel-cox/Tetris-DQN\r\n",
        "https://imake.ninja/el-tetris-an-improvement-on-pierre-dellacheries-algorithm/\r\n",
        "https://github.com/nuno-faria/tetris-ai\r\n",
        "\r\n",
        "###Notes:\r\n",
        "- get_available_moves_state_info uses a single deepcopy, may have use two separate deepcopies\r\n",
        "\r\n",
        "###General Gameplay and Terminology for NES Tetris:\r\n",
        "- NES Tetris is divided into 3 sections: Lvl 18 / Pre-transition, Lvl 19-27 / Post-transition, Lvl 28 / Kill screen\r\n",
        "- For human players, there is a limited number of lines that can conceivably be scored even by the best players, due to pieces dropping too fast. This is particularly for lvl 28 play, where each piece drops every frame, making it extremely hard to get pieces into an optimal setup. This is dubbed the \"kill screen\" where the game essentially ends for most players at that time. \r\n",
        "- Due to this, players aim to score as many points by stacking efficiently and getting as many Tetrises as possible, and the goal is to maintain a board that accomodates as many different shapes for the next piece. As NES tetris uses truly random piece selection, there is no guarantee of getting a desired piece, and often times players end up in \"droughts\" where they are not given any I / Long Bar pieces which are used to score Tetrises. Hence, an ideal board is one that can accomodate as many shapes for the next piece.\r\n",
        "- Due to the initial placement and rotation of pieces, players tend to stack their pieces to the left, keeping what is called a \"well\" or an empty column on the rightmost column. Players try to stack pieces in such a way that it results in either a relatively flat, or slanted (left high, right low), since it is easier to get a piece to the right than it is to the left. The player aims to only score from the well, and will occasionally block the well in order to not immediately lose the game (this will be explained in a while).\r\n",
        "- As players aim to score as many Tetrises, they tend to try to build as high as possible, which is considered to be \"aggressive\" since it is easier for a player to lose due to an unlucky streak of pieces. This allows players to use I pieces to score Tetrises only.\r\n",
        "- \"Burning\" is a situation where a player intentionally scores non-Tetrises so as to preserve a good board state and survive a recent set of unlucky pieces. This is non-ideal, and players only do this in order to not lose the game immediately. Players tend to block or cover their well in such circumstances \r\n",
        "- Players can employ techniques such as \"tucks\" and \"spins\", where the player inserts a piece into holes or problematic board states to fix them. Due to the small timeframe that these moves require to be executed, players generally stray away from them if they are not skilled enough to consistently execute them. Failing such techniques may result in an even worse board state. It is not expected that agents are able to naturally perform such techniques without explicitly specifying features that identify situations where these can be done. Nevertheless, skilled players are able to execute these techniques to get themselves out of terrible board states.\r\n",
        "- Generally, NES Tetris requires the player to play in a safe manner, as compared to other versions of Tetris where players are able to execute elaborate moves like spins, with ease. NES Tetris rewards players for their decision making, whilst being punishing for being indecisive and not forward-looking. Players aim to create board states that accomodates bad luck and to also play aggressively to score efficiently. It can be hard for the agent to pick up the nuances that players develop in their decision making, but it would possibly be interesting to see whether an agent can learn these or possibly develop something different.\r\n",
        "\r\n",
        "###Board State Info:\r\n",
        "Using the afforementioned overivew of gameplay, several features will be used for the agent:\r\n",
        "- Lines Cleared - How many lines will be cleared by the move. Ideally, the agent tries to clear as many lines with the move, or doesn't clear any (so that it doesn't waste lines by burning).\r\n",
        "- Bumpiness - The difference between heights of each column. Ideally, this should be a low number so that the board can accomodate different incoming pieces. If a board is too flat, then S / Z pieces can be problematic as they will produce an overhanging cell.\r\n",
        "- Holes - How many cells have an empty cell below. Ideally, this should be zero, as the board should be packed efficiently. While holes are fixable with techniques such as tucks, they are generally discouraged.\r\n",
        "- Wells - Presence of an empty column for Tetrises. Ideally, this should be present. The agent should try not to cover the well, and hence this feature will be all-or-nothing, in order to try to encourage this behavior.\r\n",
        "- Board height - How high the current board is - Ideally, this should be low, so that the agent has more leeway in its play and doesn't lose due to unlucky pieces.\r\n",
        "- Row / Column Transitions - How many filled / empty cells that are adjacent to the opposite kind with respect to row / columns. Ideally, this should be low, suggesting that pieces are either packed together well or do not have too many potholes in them:\r\n",
        "Example: \"XXXXX_____\", \"XXX_____XX\" are good, compared to \"X_X_X_X__X\", \"XX__XX_X_X\".\r\n",
        "\r\n",
        "- Piece coordinates - Location of piece and its previous location - Ideally, the agent should move only in 1 direction (to not waste moves)\r\n",
        "\r\n",
        "Possible features that can be looked into:\r\n",
        "- Hill - Board state where the board has a gradual slope from the left down to the right. Ideally, this slope is gradual so that the board is not considered bumpy and for ease of setting new pieces. \r\n",
        "- 3: Landing height\r\n",
        "- 4: Row transitions\r\n",
        "- 5: Column transitions\r\n",
        "- 6: Cumulative wells\r\n",
        "- 7: Eroded piece cells\r\n",
        "- 8: Aggregate height"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpguVW5Unxzp"
      },
      "source": [
        "# imports\r\n",
        "\r\n",
        "# board.py\r\n",
        "import random\r\n",
        "import copy\r\n",
        "\r\n",
        "# gym environment\r\n",
        "import gym\r\n",
        "import pandas\r\n",
        "from gym import spaces\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# reinforcment learning\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import statistics\r\n",
        "from pathlib import Path\r\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3fLg1VctIgo"
      },
      "source": [
        "# settings\r\n",
        "STARTING_LEVEL = 18\r\n",
        "IS_DAS_ON = False # delayed auto-shift, not implemented yet\r\n",
        "\r\n",
        "# remove moves that are in opposite directions (IE move left then move right)\r\n",
        "IS_ONE_DIRECTION_MOVEMENT = True \r\n",
        "\r\n",
        "IS_TRUE_RANDOM_PIECES = True # generates pieces randomly\r\n",
        "\r\n",
        "LOOK_FORWARD_SHIFT_MAX_VAL = 3 # considers moving left and right at most N tiles\r\n",
        "\r\n",
        "TRAIN = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTp1iebIrETt"
      },
      "source": [
        "# fixed parameters\r\n",
        "\r\n",
        "# board sizes\r\n",
        "BOARD_HEIGHT = 20\r\n",
        "BOARD_WIDTH = 10\r\n",
        "\r\n",
        "# frames required for a piece to move down 1 cell vertically\r\n",
        "FRAMES_PER_GRIDCELL_Y = [[48, \r\n",
        "   43, 38, 33, 28, 23, \r\n",
        "   18, 13, 8, 6, 5, \r\n",
        "   5, 5, 4, 4, 4, \r\n",
        "   3, 3, 3, 2, 2, \r\n",
        "   2, 2, 2, 2, 2,\r\n",
        "   2, 2, 2, 1]]\r\n",
        "\r\n",
        "# delayed auto-shift, forces first move to be delayed to 16 frames\r\n",
        "DAS_DELAY = 16\r\n",
        "\r\n",
        "FRAME_DELAY = 6 # how many frames it takes per move\r\n",
        "\r\n",
        "# initial lines needed for first level increase\r\n",
        "LINES_FIRST_LEVEL_JUMP = [[10,\r\n",
        "   20, 30, 40, 50, 60, \r\n",
        "   70, 80, 90, 100, 100,\r\n",
        "   100, 100, 100, 100, 100, \r\n",
        "   110, 120, 130, 140, 150,\r\n",
        "   160, 170, 180, 190, 200,\r\n",
        "   200, 200, 200]]\r\n",
        "\r\n",
        "LINES_PER_LEVEL = 10 # how many lines per subsequent level increase\r\n",
        "\r\n",
        "\r\n",
        "# reinforcement learning\r\n",
        "ACTION_SIZE = 5\r\n",
        "STATE_SIZE = 8\r\n",
        "\r\n",
        "# colab paths\r\n",
        "WEIGHT_PATH = os.path.join(os.getcwd(), 'weights.h5')\r\n",
        "IMAGE_PATH = os.path.join(os.getcwd(), 'model.png')\r\n",
        "LOG_DIR = os.path.join(os.getcwd(), 'logs')\r\n",
        "\r\n",
        "#WEIGHT_PATH = os.path.join(os.path.dirname(__file__), 'weights.h5')\r\n",
        "#IMAGE_PATH = os.path.join(os.path.dirname(__file__), 'model.png')\r\n",
        "#LOG_DIR = os.path.join(os.path.dirname(__file__), 'logs')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRRRYcEvUBb1"
      },
      "source": [
        "# the possible Shapes of a Piece, these are generated as a list of templates\r\n",
        "# id - the class ID of the piece\r\n",
        "# orientations - all the possible orientations\r\n",
        "class Shape:\r\n",
        "  def __init__(self, id, orientations):\r\n",
        "      self.id = id\r\n",
        "      self.max_rotations = len(orientations)\r\n",
        "      self.orientations = orientations\r\n",
        "      self.shape_coord = [] # contains the coordinates of spaces filed by the shape\r\n",
        "      \r\n",
        "      # width and height of the Piece\r\n",
        "      self.width = len(orientations[0][0])\r\n",
        "      self.height = len(orientations[0])\r\n",
        "\r\n",
        "      self.generate_shape_coord()\r\n",
        "\r\n",
        "  # returns the shape orientation of a piece, given a rotation number\r\n",
        "  def get_orientation(self, rotation):\r\n",
        "      return self.orientations[rotation % self.max_rotations]\r\n",
        "\r\n",
        "  # get the coordinates of cells occupied by a shape\r\n",
        "  def get_coord_occupied(self, rotation):\r\n",
        "      return self.shape_coord[rotation % self.max_rotations]\r\n",
        "\r\n",
        "  # generates shape coord all at once\r\n",
        "  def generate_shape_coord(self):\r\n",
        "      for rotation in range(self.max_rotations):\r\n",
        "          self.shape_coord.append(list(self.generate_shape_coord_iterative(rotation)))\r\n",
        "\r\n",
        "  # generate the occupied coordinates of a shape\r\n",
        "  def generate_shape_coord_iterative(self, rotation):\r\n",
        "      orientation = self.get_orientation(rotation)\r\n",
        "      width = self.width\r\n",
        "      height = self.height\r\n",
        "      for offset_x in range(width):\r\n",
        "        for offset_y in range(height):\r\n",
        "          if orientation[offset_y][offset_x] != ' ':\r\n",
        "            yield offset_y, offset_x\r\n",
        "\r\n",
        "  def get_id(self):\r\n",
        "    return self.id\r\n",
        "\r\n",
        "# the different possible Shapes of Pieces and their orientations\r\n",
        "# id - 0 / empty, 1 / I, 2 / O, 3 / T, 4 / S, 5 / Z, 6 / J, 7 / L\r\n",
        "# first shape is empty\r\n",
        "\r\n",
        "# shape coords\r\n",
        "SHAPE_NULL_COORDS = [[' ']]\r\n",
        "\r\n",
        "SHAPE_I_COORDS = [[\r\n",
        "    '    ',\r\n",
        "    '    ',\r\n",
        "    '####',\r\n",
        "    '    ',\r\n",
        "], [\r\n",
        "    '  # ',\r\n",
        "    '  # ',\r\n",
        "    '  # ',\r\n",
        "    '  # ',\r\n",
        "]]\r\n",
        "\r\n",
        "SHAPE_O_COORDS = [[\r\n",
        "    '##',\r\n",
        "    '##',\r\n",
        "]]\r\n",
        "\r\n",
        "SHAPE_T_COORDS = [[\r\n",
        "    '   ',\r\n",
        "    '###',\r\n",
        "    ' # ',\r\n",
        "], [\r\n",
        "    ' # ',\r\n",
        "    '## ',\r\n",
        "    ' # ',\r\n",
        "], [\r\n",
        "    ' # ',\r\n",
        "    '###',\r\n",
        "    '   ',\r\n",
        "], [\r\n",
        "    ' # ',\r\n",
        "    ' ##',\r\n",
        "    ' # ',\r\n",
        "]]\r\n",
        "\r\n",
        "SHAPE_S_COORDS = [[\r\n",
        "    '   ',\r\n",
        "    ' ##',\r\n",
        "    '## ',\r\n",
        "], [\r\n",
        "    ' # ',\r\n",
        "    ' ##',\r\n",
        "    '  #',\r\n",
        "]]\r\n",
        "\r\n",
        "SHAPE_Z_COORDS = [[\r\n",
        "    '   ',\r\n",
        "    '## ',\r\n",
        "    ' ##',\r\n",
        "], [\r\n",
        "    '  #',\r\n",
        "    ' ##',\r\n",
        "    ' # ',\r\n",
        "]]\r\n",
        "\r\n",
        "SHAPE_J_COORDS = [[\r\n",
        "    '   ',\r\n",
        "    '###',\r\n",
        "    '  #',\r\n",
        "], [\r\n",
        "    ' # ',\r\n",
        "    ' # ',\r\n",
        "    '## ',\r\n",
        "], [\r\n",
        "    '#  ',\r\n",
        "    '###',\r\n",
        "    '   ',\r\n",
        "], [\r\n",
        "    ' ##',\r\n",
        "    ' # ',\r\n",
        "    ' # ',\r\n",
        "]]\r\n",
        "\r\n",
        "SHAPE_L_COORDS = [[\r\n",
        "    '   ',\r\n",
        "    '###',\r\n",
        "    '#  ',\r\n",
        "], [\r\n",
        "    '## ',\r\n",
        "    ' # ',\r\n",
        "    ' # ',\r\n",
        "], [\r\n",
        "    '  #',\r\n",
        "    '###',\r\n",
        "    '   ',\r\n",
        "], [\r\n",
        "    ' # ',\r\n",
        "    ' # ',\r\n",
        "    ' ##',\r\n",
        "]]\r\n",
        "\r\n",
        "SHAPE_NULL = Shape(0, SHAPE_NULL_COORDS)\r\n",
        "\r\n",
        "SHAPE_I = Shape(1, SHAPE_I_COORDS)\r\n",
        "\r\n",
        "SHAPE_O = Shape(2, SHAPE_O_COORDS)\r\n",
        "\r\n",
        "SHAPE_T = Shape(3, SHAPE_T_COORDS)\r\n",
        "\r\n",
        "SHAPE_S = Shape(4, SHAPE_S_COORDS)\r\n",
        "\r\n",
        "SHAPE_Z = Shape(5, SHAPE_Z_COORDS)\r\n",
        "\r\n",
        "SHAPE_J = Shape(6, SHAPE_J_COORDS)\r\n",
        "\r\n",
        "SHAPE_L = Shape(7, SHAPE_L_COORDS)\r\n",
        "\r\n",
        "# the list of templated shapes\r\n",
        "SHAPES = [SHAPE_I, SHAPE_O, SHAPE_T, SHAPE_S, SHAPE_Z, SHAPE_J, SHAPE_L]\r\n",
        "SHAPES_ID = [SHAPE_NULL, SHAPE_I, SHAPE_O, SHAPE_T, SHAPE_S, SHAPE_Z, SHAPE_J, SHAPE_L]\r\n",
        "SHAPES_COORDS = [SHAPE_NULL_COORDS, SHAPE_I_COORDS, SHAPE_O_COORDS, SHAPE_T_COORDS, \r\n",
        "                 SHAPE_S_COORDS, SHAPE_Z_COORDS, SHAPE_J_COORDS, SHAPE_L_COORDS]\r\n",
        "SHAPES_NAMES = [\"Empty\", \"Long bar\", \"O\", \"T\", \"S\", \"Z\", \"J\", \"L\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Lrx_yYbpeB"
      },
      "source": [
        "# the piece class itself, contains data on its coordinates and rotations\r\n",
        "class Piece:\r\n",
        "  def __init__(self, id, x = 0, y = 0, rotation = 0):\r\n",
        "    self.x = x # coordinates of the top left corner of piece\r\n",
        "    self.y = y\r\n",
        "    self.id = id\r\n",
        "    self.rotation = rotation\r\n",
        "    self.shape_coords = None # the coordinates of the shape of the Piece\r\n",
        "    self.coords = []\r\n",
        "    self.prev_coords = []\r\n",
        "\r\n",
        "    # general direction that the piece has been moving\r\n",
        "    self.is_left = False\r\n",
        "    self.is_right = False\r\n",
        "\r\n",
        "  # rotates the piece, +1 is clockwise\r\n",
        "  def rotate(self, rotation_val):\r\n",
        "    if rotation_val == -1 or rotation_val == 1:\r\n",
        "      self.rotation += rotation_val\r\n",
        "      self.rotation = self.rotation % len(SHAPES_COORDS[self.id])\r\n",
        "\r\n",
        "  # update the coordinates after a move and returns both the previous and\r\n",
        "  # the new coordinates\r\n",
        "  def move(self, x, y, rotation_val):\r\n",
        "    self.prev_coords = self.coords\r\n",
        "    self.x += x\r\n",
        "    self.y += y\r\n",
        "    self.rotate(rotation_val)\r\n",
        "    self.coords = self.update_coords()\r\n",
        "\r\n",
        "    if x <= -1 and x >= -LOOK_FORWARD_SHIFT_MAX_VAL:\r\n",
        "      self.is_left = True\r\n",
        "      self.is_right = False\r\n",
        "    elif x >= 1 and x <= LOOK_FORWARD_SHIFT_MAX_VAL:\r\n",
        "      self.is_left = False\r\n",
        "      self.is_right = True\r\n",
        "\r\n",
        "    return self.prev_coords, self.coords\r\n",
        "\r\n",
        "  # returns the coordinates of cells occupied by a piece\r\n",
        "  def get_coords(self):\r\n",
        "    return self.coords\r\n",
        "\r\n",
        "  # returns the previous coordinates of cells occupied by a piece\r\n",
        "  def get_prev_coords(self):\r\n",
        "    return self.prev_coords\r\n",
        "\r\n",
        "  def get_rotation(self):\r\n",
        "    return self.rotation\r\n",
        "\r\n",
        "  # updates the coordinates of a piece based on its current x / y coordinates\r\n",
        "  def update_coords(self):\r\n",
        "    self.coords = []\r\n",
        "    self.shape_coords = SHAPES_ID[self.id].get_coord_occupied(self.rotation)\r\n",
        "    for coord in self.shape_coords:\r\n",
        "      self.coords.append([self.y + coord[0], self.x + coord[1]])\r\n",
        "\r\n",
        "    return self.coords\r\n",
        "\r\n",
        "  # simulates a move and returns updated coords without touching original data\r\n",
        "  def simulate_move(self, x, y, rotation_val):\r\n",
        "    curr_x = self.x + x\r\n",
        "    curr_y = self.y + y\r\n",
        "    curr_rotation = self.rotation + rotation_val\r\n",
        "    curr_rotation = curr_rotation % len(SHAPES_COORDS[self.id])\r\n",
        "\r\n",
        "    coords = []\r\n",
        "    shape_coords = SHAPES_ID[self.id].get_coord_occupied(curr_rotation)\r\n",
        "    for coord in shape_coords:\r\n",
        "      coords.append([curr_y + coord[0], curr_x + coord[1]])\r\n",
        "\r\n",
        "    return coords\r\n",
        "\r\n",
        "  # validates that the current state is legal\r\n",
        "  # note: not working, need to insert reference to board for var \"board\"\r\n",
        "  def is_valid_state(self):\r\n",
        "    for coord in self.coords:\r\n",
        "      x = coord[1]\r\n",
        "      y = coord[0]\r\n",
        "\r\n",
        "      if x < 0 or x >= BOARD_WIDTH or y < 0 or y >= BOARD_HEIGHT:\r\n",
        "        return False\r\n",
        "      if board[y][x] != 0 and board[y][x] != 8:\r\n",
        "        return False\r\n",
        "\r\n",
        "    return True\r\n",
        "\r\n",
        "  # calculates the amount that a piece will fall after a move\r\n",
        "  def get_y_coord_shift(self):\r\n",
        "    return 1 # return a single drop for the time being for simplicity\r\n",
        "    #return FRAME_DELAY / FRAMES_PER_GRIDCELL_Y[STARTING_LEVEL]\r\n",
        "\r\n",
        "  def get_id(self):\r\n",
        "    return self.id\r\n",
        "\r\n",
        "  # prints metadata of piece\r\n",
        "  def print_info(self):\r\n",
        "    print(\"current id is:\", self.get_id(), \"/\", SHAPES_NAMES[self.id],\r\n",
        "          \"Rotation:\", self.rotation)\r\n",
        "    print(\"coords:\", self.get_coords())\r\n",
        "\r\n",
        "    print(\"current piece arrangement\")\r\n",
        "    for line in SHAPES_COORDS[self.get_id()][self.rotation]:\r\n",
        "      print(\"|\", line, \"|\")\r\n",
        "\r\n",
        "  # prints metadata of a simulated move\r\n",
        "  def print_simulated_move(self, x, y, rotation_val):\r\n",
        "    rotation = self.rotation + rotation_val\r\n",
        "    rotation = rotation % len(SHAPES_COORDS[self.id])\r\n",
        "\r\n",
        "    print(\"current id is:\", self.get_id(), \"/\", SHAPES_NAMES[self.id],\r\n",
        "          \"Rotation:\", rotation)\r\n",
        "    print(\"coords:\", self.simulate_move(x, y, rotation_val))\r\n",
        "\r\n",
        "    print(\"current piece arrangement\")\r\n",
        "    for line in SHAPES_COORDS[self.get_id()][rotation]:\r\n",
        "      print(\"|\", line, \"|\")\r\n",
        "\r\n",
        "  # prints the current direction that the piece is heading\r\n",
        "  def print_direction(self):\r\n",
        "    if self.is_left:\r\n",
        "      print(\"left\")\r\n",
        "    elif self.is_right:\r\n",
        "      print(\"right\")\r\n",
        "    else:\r\n",
        "      print(\"neutral\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZqp9nM0UGNc"
      },
      "source": [
        "# the board contains the playing field\r\n",
        "PIECE_ID_CURRENT = 8 # used to identify the current piece\r\n",
        "PIECE_ID_EMPTY = 0\r\n",
        "PIECE_OFFSET_INITIAL = [0, 2, 0, 1, 1, 1, 1, 1] # y offset needed for initial placement\r\n",
        "\r\n",
        "MOVES = []\r\n",
        "\r\n",
        "class Board:\r\n",
        "  def __init__(self, height, width):\r\n",
        "    self.height = height\r\n",
        "    self.width = width\r\n",
        "\r\n",
        "    self.pieces_table = [[0 for i in range(width)] for j in range(height)]\r\n",
        "\r\n",
        "    self.piece = None\r\n",
        "    self.piece_next = None\r\n",
        "\r\n",
        "    self.ticks = 0 # the current frame count\r\n",
        "    self.level = STARTING_LEVEL\r\n",
        "    self.move_count = 0\r\n",
        "    self.piece_count = 0\r\n",
        "    self.line_clears = 0\r\n",
        "    self.line_clears_for_next_level = LINES_FIRST_LEVEL_JUMP[0][self.level]\r\n",
        "\r\n",
        "    self.scoring_system = self.generate_scoring_system()\r\n",
        "    self.score = 0\r\n",
        "    self.game_over = False\r\n",
        "\r\n",
        "    # unused as holding pieces are not allowed in NES tetris\r\n",
        "    self.piece_holding = None\r\n",
        "    self.piece_last = None\r\n",
        "    self.can_hold = False\r\n",
        "\r\n",
        "    # generate the random bag of pieces\r\n",
        "    self.bag = self.generate_bag()\r\n",
        "    self.piece = self.create_piece()\r\n",
        "    self.piece_next = self.create_piece()\r\n",
        "\r\n",
        "  # generates a full bag of 7 pieces \r\n",
        "  def generate_bag(self):\r\n",
        "    random_shapes = list(SHAPES)\r\n",
        "    random.shuffle(random_shapes)\r\n",
        "\r\n",
        "    bag = []\r\n",
        "    # generate bag based on whether true random or fixed\r\n",
        "    if IS_TRUE_RANDOM_PIECES:\r\n",
        "      for i in range(7):\r\n",
        "        id = random_shapes[random.randint(0, 6)].get_id()\r\n",
        "        bag.append(Piece(id))\r\n",
        "    else:\r\n",
        "      for shapes in random_shapes:\r\n",
        "        bag.append(Piece(shapes.get_id()))\r\n",
        "    return bag\r\n",
        "\r\n",
        "  # generates a random piece\r\n",
        "  def create_piece(self):\r\n",
        "    if not self.bag:\r\n",
        "      self.bag = self.generate_bag()\r\n",
        "    return self.bag.pop()\r\n",
        "\r\n",
        "  # put the new piece on the board and then update the next piece\r\n",
        "  def place_new_piece(self):\r\n",
        "    # swap piece and then fill the bag if needed\r\n",
        "    self.piece = self.piece_next\r\n",
        "    self.piece_next = self.create_piece()\r\n",
        "\r\n",
        "    # place the piece in the middle of the board\r\n",
        "    self.piece.move(int(self.width / 2), 0 - PIECE_OFFSET_INITIAL[self.piece.get_id()], 0)\r\n",
        "\r\n",
        "    if not self.update_board():\r\n",
        "      self.game_over = True\r\n",
        "      return\r\n",
        "\r\n",
        "    self.piece_count += 1\r\n",
        "    self.ticks = 0\r\n",
        "\r\n",
        "  # moves the piece, assumes that move is legal and expects a tuple of (x, y, rotation)\r\n",
        "  def move_piece(self, move, verbose = False):\r\n",
        "    self.get_current_piece().move(move[0], move[1], move[2])\r\n",
        "    self.update_board()\r\n",
        "    self.lines_cleared_recently = 0\r\n",
        "\r\n",
        "    if self.is_piece_set():\r\n",
        "      self.set_piece()\r\n",
        "      self.lines_cleared_recently = self.update_line_clear()\r\n",
        "      self.update_score(self.lines_cleared_recently)      \r\n",
        "      self.place_new_piece()\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "      self.print_current_piece_state()\r\n",
        "      print(\"cleared lines\", lines_cleared)\r\n",
        "      self.render_board()\r\n",
        "\r\n",
        "  # sets the piece on the board, assumes that piece clears check for being set\r\n",
        "  def set_piece(self):\r\n",
        "    for coord in self.piece.get_coords():\r\n",
        "      self.pieces_table[coord[0]][coord[1]] = self.piece.get_id()\r\n",
        "\r\n",
        "  # manually sets the next piece, only done when the next piece has no \r\n",
        "  # available moves, and cannot be set because of this\r\n",
        "  def force_set_next_piece(self):\r\n",
        "    if self.is_piece_set():\r\n",
        "      self.set_piece()\r\n",
        "\r\n",
        "  # updates the current piece's coords on the board, and returns status\r\n",
        "  def update_board(self):\r\n",
        "    for coord in self.piece.get_prev_coords():\r\n",
        "      if self.pieces_table[coord[0]][coord[1]] == PIECE_ID_CURRENT:\r\n",
        "        self.pieces_table[coord[0]][coord[1]] = PIECE_ID_EMPTY\r\n",
        "      else:\r\n",
        "        #self.reset_move(self.piece.get_coords(), self.piece.get_prev_coords())\r\n",
        "        return False\r\n",
        "\r\n",
        "    for coord in self.piece.get_coords():\r\n",
        "      if self.pieces_table[coord[0]][coord[1]] > PIECE_ID_EMPTY and self.pieces_table[coord[0]][coord[1]] < PIECE_ID_CURRENT:\r\n",
        "        self.reset_move(self.piece.get_coords(), self.piece.get_prev_coords())\r\n",
        "        return False\r\n",
        "      else:\r\n",
        "        self.pieces_table[coord[0]][coord[1]] = PIECE_ID_CURRENT\r\n",
        "\r\n",
        "    self.move_count += 1\r\n",
        "    return True\r\n",
        "\r\n",
        "  # runs through the board, clears any filled lines and returns how many that were cleared\r\n",
        "  def update_line_clear(self):\r\n",
        "    lines_to_clear = [] # keep track of previous lines to not double-count\r\n",
        "    lines_cleared = []\r\n",
        "\r\n",
        "    # run through all coords of the current piece to get the lines to clear\r\n",
        "    for coord in self.piece.get_coords():\r\n",
        "      if self.is_line_clear(coord[0]) and coord[0] not in lines_to_clear:\r\n",
        "        lines_to_clear.append(coord[0])\r\n",
        "\r\n",
        "    # clear the lines\r\n",
        "    lines_to_clear.reverse()\r\n",
        "    for line in lines_to_clear:\r\n",
        "      lines_cleared.append(self.clear_line(line))\r\n",
        "\r\n",
        "    # add back lines\r\n",
        "    self.add_empty_lines(len(lines_to_clear))\r\n",
        "\r\n",
        "    self.line_clears += len(lines_to_clear)\r\n",
        "\r\n",
        "    return len(lines_to_clear)\r\n",
        "\r\n",
        "  # clears the specified line\r\n",
        "  def clear_line(self, line_number):\r\n",
        "    return self.pieces_table.pop(line_number)\r\n",
        "\r\n",
        "  # adds an empty line\r\n",
        "  def add_empty_lines(self, lines_to_add):\r\n",
        "    for i in range(lines_to_add):\r\n",
        "      self.pieces_table.insert(0, [0 for i in range(self.width)])\r\n",
        "\r\n",
        "  # checks and updates level according to line clears\r\n",
        "  def update_level(self):\r\n",
        "    if self.lines >= self.line_clears_for_next_level:\r\n",
        "      self.level += 1\r\n",
        "      self.line_clears_for_next_level += 10\r\n",
        "\r\n",
        "  # resets the previous move made, because it was illegal and executed halfway\r\n",
        "  # this does not revert any overwritten cells that were previously occupied by a piece\r\n",
        "  def reset_move(self, coords, prev_coords):\r\n",
        "    # revert new state\r\n",
        "    for coord in coords:\r\n",
        "      if self.pieces_table[coord[0]][coord[1]] == PIECE_ID_CURRENT:\r\n",
        "        self.pieces_table[coord[0]][coord[1]] = PIECE_ID_EMPTY\r\n",
        "\r\n",
        "    # restore previous state\r\n",
        "    for coords in prev_coords:\r\n",
        "      self.pieces_table[coord[0]][coord[1]] = PIECE_ID_CURRENT\r\n",
        "\r\n",
        "  # update frame tick count and move the piece down\r\n",
        "  def update_frame_count(self):\r\n",
        "    if IS_DAS_ON:\r\n",
        "      self.ticks += DAS_DELAY\r\n",
        "    self.ticks += FRAME_DELAY\r\n",
        "\r\n",
        "  # updates the score based on the level\r\n",
        "  def update_score(self, lines_cleared):\r\n",
        "    self.score += self.scoring_system[lines_cleared]\r\n",
        "\r\n",
        "  # returns a list of points given for line clears for the current level\r\n",
        "  def generate_scoring_system(self):\r\n",
        "    return [0, (40 * self.level + 1), (100 * self.level + 1), (300 * self.level + 1), (1200 * self.level + 1)]\r\n",
        "\r\n",
        "  # return new final board state for state info\r\n",
        "  def generate_state_info_board(self, move, new_coords, pieces_table_copy):\r\n",
        "    # remove the piece\r\n",
        "    for coord in self.piece.get_coords():\r\n",
        "      pieces_table_copy[coord[0]][coord[1]] = PIECE_ID_EMPTY\r\n",
        "\r\n",
        "    # try to do a hard drop\r\n",
        "    hard_drop_value = 0\r\n",
        "    for i in range(self.height):\r\n",
        "      is_valid = True\r\n",
        "      for coord in new_coords:\r\n",
        "        if coord[0] + hard_drop_value + 1 >= self.height or pieces_table_copy[coord[0] + hard_drop_value + 1][coord[1]] !=  PIECE_ID_EMPTY:\r\n",
        "          is_valid = False\r\n",
        "          break\r\n",
        "\r\n",
        "      if is_valid:\r\n",
        "        hard_drop_value += 1\r\n",
        "    \r\n",
        "    # update the coords\r\n",
        "    landing_height = 0\r\n",
        "    for coord in new_coords:\r\n",
        "      pieces_table_copy[coord[0] + hard_drop_value][coord[1]] = PIECE_ID_CURRENT\r\n",
        "      landing_height = max(landing_height, coord[0] + hard_drop_value)\r\n",
        "\r\n",
        "    #print(\"move\", move)\r\n",
        "    #self.render_given_board(pieces_table_copy)\r\n",
        "\r\n",
        "    return landing_height, pieces_table_copy\r\n",
        "\r\n",
        "  # prints out the entire board\r\n",
        "  def render_board(self):\r\n",
        "    for i in range(self.height):\r\n",
        "      line_to_print = \"|\"\r\n",
        "      for j in range(self.width):\r\n",
        "        id = self.pieces_table[i][j]\r\n",
        "        if id == PIECE_ID_EMPTY:\r\n",
        "          line_to_print += \" |\"\r\n",
        "        elif id == PIECE_ID_CURRENT:\r\n",
        "          line_to_print += \"=|\"\r\n",
        "        else:\r\n",
        "          line_to_print += \"X|\"\r\n",
        "      \r\n",
        "      print(line_to_print)\r\n",
        "\r\n",
        "  # renders a given board (for simulated boards)\r\n",
        "  def render_given_board(self, board):\r\n",
        "    for i in range(self.height):\r\n",
        "      line_to_print = \"|\"\r\n",
        "      for j in range(self.width):\r\n",
        "        id = board[i][j]\r\n",
        "        if id == PIECE_ID_EMPTY:\r\n",
        "          line_to_print += \" |\"\r\n",
        "        elif id == PIECE_ID_CURRENT:\r\n",
        "          line_to_print += \"=|\"\r\n",
        "        else:\r\n",
        "          line_to_print += \"X|\"\r\n",
        "      \r\n",
        "      print(line_to_print)\r\n",
        "\r\n",
        "  def print_current_piece_state(self):\r\n",
        "    self.piece.print_info()\r\n",
        "\r\n",
        "  def print_next_piece_state(self):\r\n",
        "    self.piece_next.print_info()\r\n",
        "\r\n",
        "  # validate if the move is legal or not\r\n",
        "  def is_valid_move(self, piece, move, board, verbose = False):\r\n",
        "    # ignore the elusive O spin\r\n",
        "    if piece.get_id == 2 and move[2] != 0:\r\n",
        "      return False\r\n",
        "\r\n",
        "    coords = piece.simulate_move(move[0], move[1], move[2])\r\n",
        "    if verbose:\r\n",
        "      piece.print_simulated_move(move[0], move[1], move[2])\r\n",
        "    for coord in coords:\r\n",
        "      x = coord[1]\r\n",
        "      y = coord[0]\r\n",
        "\r\n",
        "      if x < 0 or x >= self.width or y < 0 or y >= self.height:\r\n",
        "        return False\r\n",
        "      if board[y][x] != 0 and board[y][x] != 8:\r\n",
        "        return False\r\n",
        "\r\n",
        "    return True\r\n",
        "\r\n",
        "  # returns if the piece should be set into the board\r\n",
        "  # piece is considered set if it touches another piece on the board\r\n",
        "  def is_piece_set(self):\r\n",
        "    for coord in self.piece.get_coords():\r\n",
        "      if coord[0] == (self.height - 1):\r\n",
        "        return True\r\n",
        "      elif self.pieces_table[coord[0] + 1][coord[1]] > PIECE_ID_EMPTY and self.pieces_table[coord[0] + 1][coord[1]] < PIECE_ID_CURRENT:\r\n",
        "        return True\r\n",
        "\r\n",
        "    return False\r\n",
        "\r\n",
        "  # returns if the game is over\r\n",
        "  def is_game_over(self):\r\n",
        "    return self.game_over\r\n",
        "\r\n",
        "  # returns whether the piece should drop on its own and reset tick count if true\r\n",
        "  def is_natural_drop(self):\r\n",
        "    if self.ticks > FRAMES_PER_GRIDCELL_Y[0][self.level]:\r\n",
        "      self.ticks = self.ticks % FRAMES_PER_GRIDCELL_Y[0][self.level]\r\n",
        "      return True\r\n",
        "\r\n",
        "    return False\r\n",
        "\r\n",
        "  # returns if a given line in the board is to be cleared\r\n",
        "  def is_line_clear(self, line_number):\r\n",
        "    for i in range(len(self.pieces_table[line_number])):\r\n",
        "      if self.pieces_table[line_number][i] == PIECE_ID_EMPTY:\r\n",
        "        return False \r\n",
        "    return True\r\n",
        "\r\n",
        "  # returns a list of tuples of move and state info of each possible move\r\n",
        "  # each move is a tuple of 3 elements (x offset, y offset, rotation)\r\n",
        "  # state info is a tuple of elements corresponding to information of the resulting board\r\n",
        "  def get_available_moves_state_info(self, verbose = False):\r\n",
        "    self.update_frame_count() # will move piece down naturally if needed\r\n",
        "\r\n",
        "    # left / right / down / clockwise / anti-clockwise\r\n",
        "    moves = self.generate_moves(LOOK_FORWARD_SHIFT_MAX_VAL)\r\n",
        "    \r\n",
        "    #if self.is_natural_drop():\r\n",
        "      #moves = [[-1, 1, 0], [1, 1, 0], [0, 1, 0], [0, 1, 1], [0, 1, -1]]\r\n",
        "      #moves = [[-1, 1, 0], [-2, 2, 0], [-3, 3, 0], [1, 1, 0], [2, 2, 0], [3, 3, 0], [0, 1, 0], [0, 1, 1], [0, 1, -1]]\r\n",
        "    #else:\r\n",
        "      #moves = [[-1, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1], [0, 0, -1]]\r\n",
        "      #moves = [[-1, 0, 0], [-2, 0, 0], [-3, 0, 0], [1, 0, 0], [2, 0, 0], [3, 0 ,0], [0, 1, 0], [0, 0, 1], [0, 0, -1]]\r\n",
        "    \r\n",
        "\r\n",
        "    # remove moves that are in opposite direction of the piece direction\r\n",
        "    if IS_ONE_DIRECTION_MOVEMENT:\r\n",
        "      if self.piece.is_left:\r\n",
        "        for i in range(LOOK_FORWARD_SHIFT_MAX_VAL):\r\n",
        "          moves.pop(LOOK_FORWARD_SHIFT_MAX_VAL)\r\n",
        "      elif self.piece.is_right:\r\n",
        "        for i in range(LOOK_FORWARD_SHIFT_MAX_VAL):\r\n",
        "          moves.pop(0)\r\n",
        "      \r\n",
        "    legal_moves = []\r\n",
        "\r\n",
        "    for move in moves:\r\n",
        "      test_pieces_table = copy.deepcopy(self.pieces_table)\r\n",
        "      if self.is_valid_move(self.piece, move, test_pieces_table, verbose = verbose):\r\n",
        "        legal_moves.append([move, self.get_board_info(move, test_pieces_table, verbose = verbose)])\r\n",
        "    \r\n",
        "    return legal_moves\r\n",
        "\r\n",
        "  # returns the set of possible moves based on the level and how many shifts are considered\r\n",
        "  def generate_moves(self, look_forward_shift_val):\r\n",
        "    moves = []\r\n",
        "    moves_left = []\r\n",
        "    moves_right = []\r\n",
        "\r\n",
        "    # add left / right\r\n",
        "    for i in range(look_forward_shift_val):\r\n",
        "      drop = (i + 1) * (3 / FRAMES_PER_GRIDCELL_Y[0][self.level])\r\n",
        "      moves_left.append([(i + 1), int(drop), 0])\r\n",
        "      moves_right.append([-(i + 1), int(drop), 0])\r\n",
        "\r\n",
        "    # add down / rotates\r\n",
        "    for move in moves_left:\r\n",
        "      moves.append(move)\r\n",
        "    for move in moves_right:\r\n",
        "      moves.append(move)\r\n",
        "    moves.append([0, 1, 0])\r\n",
        "    moves.append([0, int(3 / FRAMES_PER_GRIDCELL_Y[0][self.level]), 1])\r\n",
        "    moves.append([0, int(3 / FRAMES_PER_GRIDCELL_Y[0][self.level]), -1])\r\n",
        "\r\n",
        "    return moves\r\n",
        "\r\n",
        "  # returns the state info of the board, to be passed into the agent\r\n",
        "  # more state info can be given to the agent if needed:\r\n",
        "  # the piece is moved and then hard dropped to evaluate how good the move may be\r\n",
        "  def get_board_info(self, move, pieces_table_copy, verbose = False):\r\n",
        "    # get the new board state\r\n",
        "    coords = self.piece.simulate_move(move[0], move[1], move[2]) # the new coords\r\n",
        "    landing_height, simulated_pieces_table = self.generate_state_info_board(move, coords, pieces_table_copy)\r\n",
        "\r\n",
        "    # Lines Cleared - How many lines will be cleared by the move\r\n",
        "    lines_cleared = self.get_state_lines_cleared(simulated_pieces_table, coords)\r\n",
        "\r\n",
        "    # Wells - Presence of an empty column for Tetrises\r\n",
        "    wells = self.get_state_wells(simulated_pieces_table)\r\n",
        "\r\n",
        "    # Board height - How high the current board is\r\n",
        "    board_height = self.get_state_board_height(simulated_pieces_table)\r\n",
        "\r\n",
        "    # Bumpiness - The difference between heights of each column\r\n",
        "    bumpiness = self.get_state_bumpiness(simulated_pieces_table)\r\n",
        "\r\n",
        "    # Holes - How many cells have an empty cell below\r\n",
        "    holes = self.get_state_holes(simulated_pieces_table)\r\n",
        "\r\n",
        "    # Row Transitions / Column Transitions - How many empty / filled cells are \r\n",
        "    # adjacent to the opposite on the same row\r\n",
        "    row_transitions, col_transitions = self.get_state_transitions(simulated_pieces_table)\r\n",
        "\r\n",
        "    # Piece coordinates - Location of piece and its previous location\r\n",
        "    coord_x_new = coords[0][1]\r\n",
        "    coord_y_new = coords[0][0]\r\n",
        "\r\n",
        "    if verbose:\r\n",
        "      print(\"lines cleared\", lines_cleared, \"wells\", wells)\r\n",
        "      print(\"board height\", board_height, \"bumpiness\", bumpiness)\r\n",
        "      print(\"holes\", holes)\r\n",
        "      print(\"coords new (x, y)\" , coord_x_new, coord_y_new, \"coords (x, y)\", coord_x, coord_y)\r\n",
        "\r\n",
        "    #return [lines_cleared, wells, board_height, bumpiness, holes, \r\n",
        "    #        coord_x_new, row_transitions, col_transitions]\r\n",
        "    return [landing_height, lines_cleared, holes, row_transitions, col_transitions, \r\n",
        "            bumpiness, board_height, coord_x_new]\r\n",
        "\r\n",
        "  def get_state_lines_cleared(self, board, coords):\r\n",
        "    lines_to_clear = [] # keep track of previous lines to not double-count\r\n",
        "\r\n",
        "    # run through all coords of the current piece to get the lines to clear\r\n",
        "    for coord in coords:\r\n",
        "      if coord[0] not in lines_to_clear:\r\n",
        "        is_cleared = True\r\n",
        "        for j in range(self.width): # by col\r\n",
        "          if board[coord[0]][j] == PIECE_ID_EMPTY:\r\n",
        "            is_cleared = False\r\n",
        "            break\r\n",
        "\r\n",
        "        if is_cleared:\r\n",
        "          lines_to_clear.append(coord[0])\r\n",
        "\r\n",
        "    return len(lines_to_clear)\r\n",
        "  \r\n",
        "  # returns how many wells there are in the board\r\n",
        "  def get_state_wells(self, board):\r\n",
        "    wells = 0\r\n",
        "    for i in range(len(board[0])): # column\r\n",
        "      is_well = True\r\n",
        "      for j in range(len(board)): # row\r\n",
        "        if board[j][i] != PIECE_ID_EMPTY:\r\n",
        "          is_well = False\r\n",
        "          break\r\n",
        "\r\n",
        "      if is_well:\r\n",
        "        wells += 1\r\n",
        "\r\n",
        "    return wells\r\n",
        "\r\n",
        "  # returns the average height of all non-empty columns\r\n",
        "  def get_state_board_height(self, board):\r\n",
        "    non_empty_columns = 0\r\n",
        "    total_height = 0\r\n",
        "\r\n",
        "    for i in range(len(board[0])): # column\r\n",
        "      height = 0\r\n",
        "      for j in range(len(board)): # row\r\n",
        "        if board[j][i] != PIECE_ID_EMPTY:\r\n",
        "          height += 1\r\n",
        "      if height == 0:\r\n",
        "        non_empty_columns += 1\r\n",
        "      else:\r\n",
        "        total_height += height\r\n",
        "\r\n",
        "    return total_height / (self.width - non_empty_columns)\r\n",
        "\r\n",
        "  # returns the sum total of differences between height of each column and its adjacent one\r\n",
        "  def get_state_bumpiness(self, board):\r\n",
        "    bumpiness = 0\r\n",
        "\r\n",
        "    # iterate through each column\r\n",
        "    for i in range(self.width):\r\n",
        "      prev_height = 0\r\n",
        "      height = 0\r\n",
        "      for j in range(self.height):\r\n",
        "        if board[j][i] != PIECE_ID_EMPTY: # get the first non-empty cell\r\n",
        "          height = j\r\n",
        "          if i != 0:\r\n",
        "            bumpiness += abs(height - prev_height)\r\n",
        "          prev_height = height\r\n",
        "\r\n",
        "          break\r\n",
        "      \r\n",
        "    return bumpiness\r\n",
        "\r\n",
        "  # returns how many cells that have an empty cell below\r\n",
        "  def get_state_holes(self, board):\r\n",
        "    holes = 0\r\n",
        "\r\n",
        "    for i in range(self.width):\r\n",
        "      is_overhang = False # presence of a cell above that is filled\r\n",
        "      for j in range(self.height):\r\n",
        "        if board[j][i] != PIECE_ID_EMPTY:\r\n",
        "          is_overhang = True\r\n",
        "        elif is_overhang and board[j][i] == PIECE_ID_EMPTY:\r\n",
        "          holes += 1\r\n",
        "\r\n",
        "    return holes\r\n",
        "\r\n",
        "  # returns the row and col transitions\r\n",
        "  # the aggregate number of different cells adjacent to one another in row / col\r\n",
        "  def get_state_transitions(self, board):\r\n",
        "    row_transitions = 0\r\n",
        "    col_transitions = 0\r\n",
        "\r\n",
        "    is_next_row_empty = True\r\n",
        "    is_next_col_empty = True\r\n",
        "\r\n",
        "    for i in range(self.height - 1):\r\n",
        "      for j in range(self.width):\r\n",
        "        # row transition\r\n",
        "        if j != self.width - 1:\r\n",
        "          if board[i][j] == PIECE_ID_EMPTY and board[i][j + 1] != PIECE_ID_EMPTY:\r\n",
        "            row_transitions += 1\r\n",
        "          elif board[i][j] != PIECE_ID_EMPTY and board[i][j + 1] == PIECE_ID_EMPTY:\r\n",
        "            row_transitions += 1\r\n",
        "\r\n",
        "        if board[i + 1][j] == PIECE_ID_EMPTY and board[i + 1][j] != PIECE_ID_EMPTY:\r\n",
        "          col_transitions += 1\r\n",
        "        elif board[i + 1][j] != PIECE_ID_EMPTY and board[i + 1][j] == PIECE_ID_EMPTY:\r\n",
        "          col_transitions += 1\r\n",
        "\r\n",
        "    return row_transitions, col_transitions\r\n",
        "\r\n",
        "\r\n",
        "  # gets the current piece\r\n",
        "  def get_current_piece(self):\r\n",
        "    return self.piece\r\n",
        "\r\n",
        "  def get_piece_count(self):\r\n",
        "    return self.piece_count\r\n",
        "\r\n",
        "  def get_move_count(self):\r\n",
        "    return self.move_count\r\n",
        "\r\n",
        "  def get_lines_cleared(self):\r\n",
        "    return self.lines_cleared\r\n",
        "\r\n",
        "  def get_level(self):\r\n",
        "    return self.level\r\n",
        "\r\n",
        "  def get_score(self):\r\n",
        "    return self.score\r\n",
        "\r\n",
        "  # return the number of lines that have been cleared in the most recent move\r\n",
        "  def get_lines_cleared_recently(self):\r\n",
        "    return self.lines_cleared_recently\r\n",
        "\r\n",
        "  # returns increase in score from lines cleared\r\n",
        "  def get_score_increase(self, lines_cleared):\r\n",
        "    return self.scoring_system[lines_cleared]\r\n",
        "\r\n",
        "  def get_deep_copy_pieces_table(self):\r\n",
        "    return copy.deepcopy(self.pieces_table)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYFeUQlBm-If"
      },
      "source": [
        "# gym environment that follows gym interface\"\"\"\r\n",
        "class NesTetrisEnv(gym.Env):\r\n",
        "  metadata = {'render.modes': ['console']}\r\n",
        "\r\n",
        "  def __init__(self):\r\n",
        "    super(NesTetrisEnv, self).__init__()\r\n",
        "    # Define action and observation space\r\n",
        "\r\n",
        "    # left / right / down / rotate clockwise / anti-clockwise\r\n",
        "    self.action_space = spaces.Discrete(ACTION_SIZE)\r\n",
        "\r\n",
        "    # [lines_cleared, wells, board_height, bumpiness, holes, coord_x_new, coord_y_new, coord_x, coord_y, piece_id, piece_rotation]\r\n",
        "    self.observation_space = spaces.Discrete(STATE_SIZE)\r\n",
        "\r\n",
        "  # Execute one time step within the environment\r\n",
        "  # action takes in move data (x, y, rotation)\r\n",
        "  def step(self, action):\r\n",
        "    # run the action\r\n",
        "    self.board.move_piece(action, verbose = False)\r\n",
        "\r\n",
        "    # return available moves with state info\r\n",
        "    moves = self.board.get_available_moves_state_info()\r\n",
        "\r\n",
        "    done = self.board.is_game_over()\r\n",
        "\r\n",
        "    reward = 1\r\n",
        "    reward += self.board.get_score_increase(self.board.get_lines_cleared_recently())\r\n",
        "    if done:\r\n",
        "      reward -= 5\r\n",
        "\r\n",
        "    return np.array(moves), reward, done, {}\r\n",
        "    \r\n",
        "  # reset the state of the environment to an initial state and return initial observation\r\n",
        "  def reset(self, verbose = False):\r\n",
        "    self.board = Board(BOARD_HEIGHT, BOARD_WIDTH)\r\n",
        "    self.board.place_new_piece()\r\n",
        "    \r\n",
        "    if verbose:\r\n",
        "      self.board.render_board()\r\n",
        "      self.board.print_current_piece_state()\r\n",
        "\r\n",
        "    return np.array(self.board.get_available_moves_state_info())\r\n",
        "    \r\n",
        "  # Render the environment to the screen\r\n",
        "  def render(self, mode='human', close=False):\r\n",
        "    self.board.render_board()\r\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiKfM1WNel_r"
      },
      "source": [
        "  # reinforcement learning\r\n",
        "  class ExperienceBuffer:\r\n",
        "    def __init__(self, buffer_size=20000):\r\n",
        "      self.buffer = []\r\n",
        "      self.buffer_size = buffer_size\r\n",
        "\r\n",
        "    def add(self, experience):\r\n",
        "      if len(self.buffer) > self.buffer_size:\r\n",
        "        self.buffer.pop(-1)\r\n",
        "      self.buffer.append(experience)\r\n",
        "\r\n",
        "    def sample(self, size):\r\n",
        "      return random.sample(self.buffer, size)\r\n",
        "\r\n",
        "  class Network:\r\n",
        "    def __init__(self, state_size=STATE_SIZE, discount=1, epsilon=1, epsilon_min=0.0001, epsilon_episode_limit=500):\r\n",
        "      self.state_size = state_size\r\n",
        "      self.model = self.create_model()\r\n",
        "      self.discount = discount\r\n",
        "      self.epsilon = epsilon\r\n",
        "      self.epsilon_min = epsilon_min\r\n",
        "      self.epsilon_episode_limit = epsilon_episode_limit\r\n",
        "      self.epsilon_decay = (epsilon - epsilon_min) / epsilon_episode_limit\r\n",
        "      self.experiences = ExperienceBuffer()\r\n",
        "      self.tensorboard = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR,\r\n",
        "                                                        histogram_freq=1000,\r\n",
        "                                                        write_graph=True,\r\n",
        "                                                        write_images=True)\r\n",
        "      \r\n",
        "    # setups and returns model\r\n",
        "    def create_model(self, verbose = False):\r\n",
        "      model =  tf.keras.models.Sequential([\r\n",
        "          tf.keras.layers.Dense(32, input_dim=self.state_size, activation='relu'),\r\n",
        "          tf.keras.layers.Dense(16, activation='relu'),\r\n",
        "          tf.keras.layers.Dense(16, activation='relu'),\r\n",
        "          tf.keras.layers.Dense(1, activation='linear'),\r\n",
        "      ])\r\n",
        "\r\n",
        "      '''\r\n",
        "      \r\n",
        "      model =  tf.keras.models.Sequential([\r\n",
        "          tf.keras.layers.Dense(64, input_dim=self.state_size, activation='relu'),\r\n",
        "          tf.keras.layers.Dense(64, activation='relu'),\r\n",
        "          tf.keras.layers.Dense(32, activation='relu'),\r\n",
        "          tf.keras.layers.Dense(1, activation='linear'),\r\n",
        "      ])\r\n",
        "      '''\r\n",
        "\r\n",
        "      model.compile(optimizer='adam', loss='mse', metrics=['mean_squared_error'])\r\n",
        "\r\n",
        "      if verbose:\r\n",
        "        model.summary()\r\n",
        "\r\n",
        "      tf.keras.utils.plot_model(model, IMAGE_PATH, show_shapes=True)\r\n",
        "\r\n",
        "      return model\r\n",
        "\r\n",
        "    # returns the best move, unless agent decides to explore\r\n",
        "    def act(self, states):\r\n",
        "      # no moves\r\n",
        "      if len(states) == 0:\r\n",
        "        return None, None\r\n",
        "      # explore\r\n",
        "      if random.uniform(0, 1) < self.epsilon:\r\n",
        "        return np.array(states[random.randint(0, len(states) - 1)])\r\n",
        "\r\n",
        "      best_rating = None\r\n",
        "      best_state = None\r\n",
        "      state_to_use = 0\r\n",
        "\r\n",
        "      ratings = self.predict_ratings(states)\r\n",
        "      for i in range(len(states)):\r\n",
        "        if best_rating is None or (best_rating is not None and ratings[i] > best_rating):\r\n",
        "          best_rating = ratings[i]\r\n",
        "          state_to_use = i\r\n",
        "\r\n",
        "      return states[state_to_use][0], states[state_to_use][1]\r\n",
        "\r\n",
        "    # runs the state through the NN, and return the outputs\r\n",
        "    def predict_ratings(self, states):\r\n",
        "      if len(states[0]) == 1:\r\n",
        "        inputs = np.array(states)\r\n",
        "      else:\r\n",
        "        inputs = np.array([state[1] for state in states])\r\n",
        "\r\n",
        "      # run the prediction, catch ValueError when states contain List() objs because\r\n",
        "      # the state contains moves / board info, which are of different dimensions\r\n",
        "      # and are not convertible under np.array(), and end up as List()s\r\n",
        "      try:\r\n",
        "        predictions = self.model.predict(states)\r\n",
        "      except ValueError:\r\n",
        "        predictions = self.model.predict(np.array([state[1] for state in states]))\r\n",
        "\r\n",
        "      return [predict[0] for predict in predictions]\r\n",
        "\r\n",
        "    # trains for a given number of episodes, returns the amount of steps, reward and scores\r\n",
        "    def train(self, env, episodes = 1):\r\n",
        "      rewards = []\r\n",
        "      scores = []\r\n",
        "      steps = 0\r\n",
        "\r\n",
        "      for episode in range(episodes):\r\n",
        "        obs = env.reset()\r\n",
        "        previous_state = env.board.get_board_info([0, 0, 0], env.board.get_deep_copy_pieces_table())\r\n",
        "\r\n",
        "        done = False\r\n",
        "        total_reward = 0\r\n",
        "\r\n",
        "        while not done:\r\n",
        "          action, state = self.act(obs)\r\n",
        "          if action is None:\r\n",
        "            done = True\r\n",
        "            steps += 1\r\n",
        "            total_reward -= 5\r\n",
        "            continue\r\n",
        "\r\n",
        "          obs, reward, done, info = env.step(action)\r\n",
        "          self.experiences.add((previous_state, reward, state, done))\r\n",
        "          previous_state = state\r\n",
        "          steps += 1\r\n",
        "          total_reward += reward\r\n",
        "\r\n",
        "        rewards.append(total_reward)\r\n",
        "        scores.append(env.board.get_score())\r\n",
        "\r\n",
        "        self.learn()\r\n",
        "\r\n",
        "      return [steps, rewards, scores]\r\n",
        "\r\n",
        "    # load from local .h5\r\n",
        "    def load(self):\r\n",
        "      if Path(WEIGHT_PATH).is_file():\r\n",
        "        self.model.load_weights(WEIGHT_PATH)\r\n",
        "\r\n",
        "    # save to local .h5\r\n",
        "    def save(self):\r\n",
        "      if not os.path.exists(os.path.dirname(WEIGHT_PATH)):\r\n",
        "        os.makedirs(os.path.dirname(WEIGHT_PATH))\r\n",
        "\r\n",
        "      self.model.save_weights(WEIGHT_PATH)\r\n",
        "\r\n",
        "    # model learns about reent experiences\r\n",
        "    # batch_size corresponds to the random experiences from experience buffer\r\n",
        "    def learn(self, batch_size = 512, epochs = 1):\r\n",
        "      if len(self.experiences.buffer) < batch_size: # buffer too small, return\r\n",
        "        return\r\n",
        "\r\n",
        "      batch = self.experiences.sample(batch_size)\r\n",
        "      train_x = []\r\n",
        "      train_y = []\r\n",
        "\r\n",
        "      states = np.array([[[0, 0, 0], x[2]] for x in batch])\r\n",
        "      ratings = self.predict_ratings(states)\r\n",
        "\r\n",
        "      for i, (previous_state, reward, next_state, done) in enumerate(batch):\r\n",
        "        if not done:\r\n",
        "          rating = ratings[i]\r\n",
        "          q = reward + self.discount * rating\r\n",
        "        else:\r\n",
        "          q = reward\r\n",
        "        train_x.append(previous_state)\r\n",
        "        train_y.append(q)\r\n",
        "\r\n",
        "      self.model.fit(np.array(train_x), np.array(train_y), batch_size=len(train_x), verbose=0,\r\n",
        "                    epochs=epochs, callbacks=[self.tensorboard])\r\n",
        "      self.epsilon = max(self.epsilon_min, self.epsilon - self.epsilon_decay)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0qRoBWh7F7",
        "outputId": "f79ed3cd-2463-4ce9-8862-e0b3b355d841"
      },
      "source": [
        "# test code\r\n",
        "'''\r\n",
        "# non-env testing\r\n",
        "# create the board\r\n",
        "test_board = Board(BOARD_HEIGHT, BOARD_WIDTH)\r\n",
        "\r\n",
        "# test the rendering\r\n",
        "test_board.place_new_piece()\r\n",
        "test_board.render_board()\r\n",
        "test_board.print_current_piece_state()\r\n",
        "\r\n",
        "# runs the game\r\n",
        "while not test_board.is_game_over():\r\n",
        "\r\n",
        "  moves = test_board.get_available_moves_state_info(verbose=False)\r\n",
        "  if len(moves) is not 0:\r\n",
        "    move_num = random.randint(0, len(moves) - 1)\r\n",
        "    #print(moves[move_num])\r\n",
        "    #print(test_board.piece.print_direction())\r\n",
        "    test_board.move_piece(moves[move_num][0], verbose = False)\r\n",
        "  else:\r\n",
        "    print(\"topoff\")\r\n",
        "    break\r\n",
        "\r\n",
        "print(\"final\")\r\n",
        "test_board.render_board()\r\n",
        "test_board.print_current_piece_state()\r\n",
        "print(\"pieces used\", test_board.get_piece_count())\r\n",
        "print(\"moves used\", test_board.get_move_count())\r\n",
        "'''\r\n",
        "\r\n",
        "# test env\r\n",
        "'''\r\n",
        "env = NesTetrisEnv()\r\n",
        "obs = env.reset()\r\n",
        "network = Network()\r\n",
        "\r\n",
        "done = False\r\n",
        "total_games = 0\r\n",
        "total_steps = 0\r\n",
        "#print(\"obs\", obs)\r\n",
        "\r\n",
        "while not done:\r\n",
        "  # get the next action\r\n",
        "  if len(obs) != 0:\r\n",
        "    move_num = random.randint(0, len(obs) - 1)\r\n",
        "  else:\r\n",
        "    print(\"no more moves\")\r\n",
        "    break\r\n",
        "\r\n",
        "  #action, state = network.act(obs) # when the DQN is finished\r\n",
        "  obs, reward, done, info = env.step(obs[move_num][0])\r\n",
        "  env.render()\r\n",
        "'''\r\n",
        "if TRAIN:\r\n",
        "  total_episodes = 1000\r\n",
        "  epsilon_episode_finish_rate = 0.5\r\n",
        "  epsilon_episode_limit = total_episodes * epsilon_episode_finish_rate\r\n",
        "    \r\n",
        "  env = NesTetrisEnv()\r\n",
        "  obs = env.reset()\r\n",
        "  network = Network(epsilon=0.95, epsilon_episode_limit=epsilon_episode_limit)\r\n",
        "  #network.load()\r\n",
        "\r\n",
        "  done = False\r\n",
        "  total_games = 0\r\n",
        "  total_steps = 0\r\n",
        "  episodes = 50\r\n",
        "\r\n",
        "  while not done:\r\n",
        "    time_start = time.time()\r\n",
        "    steps, rewards, scores = network.train(env, episodes=episodes)\r\n",
        "    total_games += len(scores)\r\n",
        "    total_steps += steps\r\n",
        "    network.save()\r\n",
        "\r\n",
        "\r\n",
        "    print(\"==================\")\r\n",
        "    print(\"* Total Games: \", total_games)\r\n",
        "    print(\"* Took total / per game (seconds):\", time.time() - time_start, \"/\", (time.time() - time_start) / episodes)\r\n",
        "    print(\"* Total Steps: \", total_steps)\r\n",
        "    print(\"* Epsilon: \", network.epsilon)\r\n",
        "    print(\"*\")\r\n",
        "    print(\"* Average: \", sum(rewards) / len(rewards), \"/\", sum(scores) / len(scores))\r\n",
        "    print(\"* Median: \", statistics.median(rewards), \"/\", statistics.median(scores))\r\n",
        "    print(\"* Mean: \", statistics.mean(rewards), \"/\", statistics.mean(scores))\r\n",
        "    print(\"* Min: \", min(rewards), \"/\", min(scores))\r\n",
        "    print(\"* Max: \", max(rewards), \"/\", max(scores))\r\n",
        "    print(\"==================\")\r\n",
        "\r\n",
        "    if total_games >=  total_episodes:\r\n",
        "      done = True \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:152: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================\n",
            "* Total Games:  50\n",
            "* Took total / per game (seconds): 43.692585945129395 / 0.873851728439331\n",
            "* Total Steps:  6527\n",
            "* Epsilon:  0.8626091999999996\n",
            "*\n",
            "* Average:  125.38 / 0.0\n",
            "* Median:  122.0 / 0.0\n",
            "* Mean:  125.38 / 0\n",
            "* Min:  86 / 0\n",
            "* Max:  187 / 0\n",
            "==================\n",
            "==================\n",
            "* Total Games:  100\n",
            "* Took total / per game (seconds): 71.72825694084167 / 1.4345651483535766\n",
            "* Total Steps:  13472\n",
            "* Epsilon:  0.7676191999999993\n",
            "*\n",
            "* Average:  133.72 / 0.0\n",
            "* Median:  132.0 / 0.0\n",
            "* Mean:  133.72 / 0\n",
            "* Min:  96 / 0\n",
            "* Max:  175 / 0\n",
            "==================\n",
            "==================\n",
            "* Total Games:  150\n",
            "* Took total / per game (seconds): 113.31314420700073 / 2.2662629222869874\n",
            "* Total Steps:  21517\n",
            "* Epsilon:  0.6726291999999989\n",
            "*\n",
            "* Average:  170.14 / 14.42\n",
            "* Median:  159.0 / 0.0\n",
            "* Mean:  170.14 / 14.42\n",
            "* Min:  107 / 0\n",
            "* Max:  933 / 721\n",
            "==================\n",
            "==================\n",
            "* Total Games:  200\n",
            "* Took total / per game (seconds): 151.47299551963806 / 3.0294599199295043\n",
            "* Total Steps:  29932\n",
            "* Epsilon:  0.5776391999999986\n",
            "*\n",
            "* Average:  192.04 / 28.84\n",
            "* Median:  162.0 / 0.0\n",
            "* Mean:  192.04 / 28.84\n",
            "* Min:  90 / 0\n",
            "* Max:  930 / 721\n",
            "==================\n",
            "==================\n",
            "* Total Games:  250\n",
            "* Took total / per game (seconds): 198.33193397521973 / 3.9666387033462525\n",
            "* Total Steps:  39072\n",
            "* Epsilon:  0.4826491999999982\n",
            "*\n",
            "* Average:  206.38 / 28.84\n",
            "* Median:  178.5 / 0.0\n",
            "* Mean:  206.38 / 28.84\n",
            "* Min:  142 / 0\n",
            "* Max:  946 / 721\n",
            "==================\n",
            "==================\n",
            "* Total Games:  300\n",
            "* Took total / per game (seconds): 245.11269545555115 / 4.902253932952881\n",
            "* Total Steps:  48678\n",
            "* Epsilon:  0.38765919999999787\n",
            "*\n",
            "* Average:  215.78 / 28.84\n",
            "* Median:  192.0 / 0.0\n",
            "* Mean:  215.78 / 28.84\n",
            "* Min:  124 / 0\n",
            "* Max:  928 / 721\n",
            "==================\n",
            "==================\n",
            "* Total Games:  350\n",
            "* Took total / per game (seconds): 304.58846163749695 / 6.091769247055054\n",
            "* Total Steps:  59085\n",
            "* Epsilon:  0.2926691999999975\n",
            "*\n",
            "* Average:  246.18 / 43.26\n",
            "* Median:  202.0 / 0.0\n",
            "* Mean:  246.18 / 43.26\n",
            "* Min:  151 / 0\n",
            "* Max:  975 / 721\n",
            "==================\n",
            "==================\n",
            "* Total Games:  400\n",
            "* Took total / per game (seconds): 357.6358394622803 / 7.152716822624207\n",
            "* Total Steps:  69853\n",
            "* Epsilon:  0.19767919999999717\n",
            "*\n",
            "* Average:  282.3 / 72.1\n",
            "* Median:  214.0 / 0.0\n",
            "* Mean:  282.3 / 72.1\n",
            "* Min:  126 / 0\n",
            "* Max:  969 / 721\n",
            "==================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsmrRRgqZrA2"
      },
      "source": [
        "\r\n",
        "env = NesTetrisEnv()\r\n",
        "env.reset()\r\n",
        "print(env.board.generate_moves(3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsREk9EMp9sd"
      },
      "source": [
        "# load and test\r\n",
        "env = NesTetrisEnv()\r\n",
        "obs = env.reset()\r\n",
        "network = Network()\r\n",
        "network.load()\r\n",
        "\r\n",
        "done = False\r\n",
        "total_games = 0\r\n",
        "total_steps = 0\r\n",
        "\r\n",
        "print(\"=====obs=====\")\r\n",
        "print(obs)\r\n",
        "env.render()\r\n",
        "\r\n",
        "while not done and total_steps <= 10000:\r\n",
        "  # get the next action\r\n",
        "  if len(obs) != 0:\r\n",
        "    #move_num = random.randint(0, len(obs) - 1)\r\n",
        "    action, state = network.act(obs)\r\n",
        "  else:\r\n",
        "    print(\"no more moves\")\r\n",
        "    break\r\n",
        "\r\n",
        "  #action, state = network.act(obs) # when the DQN is finished\r\n",
        "  obs, reward, done, info = env.step(action)\r\n",
        "\r\n",
        "  # obs = [landing_height, lines_cleared, holes, row_transitions, col_transitions]\r\n",
        "  print(\"=====obs=====\")\r\n",
        "  print(obs)\r\n",
        "  env.render()\r\n",
        "  print(\"=====================\")\r\n",
        "  total_steps += 1\r\n",
        "\r\n",
        "print(\"=====finished=====\")\r\n",
        "env.render()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}